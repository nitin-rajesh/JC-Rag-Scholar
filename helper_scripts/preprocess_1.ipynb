{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9917dde6",
        "outputId": "eb621505-84c7-4742-ec5f-50198ecf71d6"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m235.5/235.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04ade24",
        "outputId": "fd001b62-3bf9-40a1-f9ce-76188606c10d"
      },
      "source": [
        "!pip install pdfplumber"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict\n",
        "from unidecode import unidecode"
      ],
      "metadata": {
        "id": "4A6ift6BtL81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d95d6c8",
        "outputId": "da9eba12-03d6-4007-8c43-84948d26b7fd"
      },
      "source": [
        "url = 'https://folger-main-site-assets.s3.amazonaws.com/uploads/2022/11/julius-caesar_PDF_FolgerShakespeare.pdf'\n",
        "pdf_filename = 'julius_caesar.pdf'\n",
        "!wget -O {pdf_filename} {url}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-22 15:11:12--  https://folger-main-site-assets.s3.amazonaws.com/uploads/2022/11/julius-caesar_PDF_FolgerShakespeare.pdf\n",
            "Resolving folger-main-site-assets.s3.amazonaws.com (folger-main-site-assets.s3.amazonaws.com)... 3.5.25.23, 16.15.176.200, 54.231.129.161, ...\n",
            "Connecting to folger-main-site-assets.s3.amazonaws.com (folger-main-site-assets.s3.amazonaws.com)|3.5.25.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 617669 (603K) [application/pdf]\n",
            "Saving to: ‘julius_caesar.pdf’\n",
            "\n",
            "julius_caesar.pdf   100%[===================>] 603.19K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-22 15:11:12 (6.14 MB/s) - ‘julius_caesar.pdf’ saved [617669/617669]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f97b4df",
        "outputId": "4bc6032c-fd93-4cdd-8267-87124c2c9841"
      },
      "source": [
        "pages_data_plumber = []\n",
        "\n",
        "with pdfplumber.open(pdf_filename) as pdf:\n",
        "    for i, page in enumerate(pdf.pages):\n",
        "        text = page.extract_text()\n",
        "        pages_data_plumber.append({\n",
        "            'page': i + 1,  # Page numbers are 1-based\n",
        "            'raw': text\n",
        "        })\n",
        "\n",
        "output_json_filename_plumber = 'julius-caesar.json'\n",
        "with open(output_json_filename_plumber, 'w', encoding='utf-8') as f:\n",
        "    json.dump(pages_data_plumber, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Extracted text from {len(pages_data_plumber)} pages using pdfplumber and saved to '{output_json_filename_plumber}'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text from 106 pages using pdfplumber and saved to 'julius-caesar.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = '/content/julius-caesar.json'"
      ],
      "metadata": {
        "id": "FzEYOCyTt1jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHARACTERS = {\n",
        "    'FLAVIUS', 'MARULLUS', 'CARPENTER', 'COBBLER', 'CAESAR', 'CALPHURNIA',\n",
        "    'BRUTUS', 'PORTIA', 'LUCIUS', 'CASSIUS', 'CASCA', 'CINNA', 'DECIUS',\n",
        "    'LIGARIUS', 'METELLUS', 'CIMBER', 'TREBONIUS', 'CICERO', 'PUBLIUS',\n",
        "    'POPILIUS', 'LENA', 'ANTONY', 'LEPIDUS', 'OCTAVIUS', 'SERVANT',\n",
        "    'SOOTHSAYER', 'ARTEMIDORUS', 'LUCILIUS', 'TITINIUS', 'MESSALA',\n",
        "    'VARRO', 'CLAUDIUS', 'CATO', 'STRATO', 'VOLUMNIUS', 'DARDANUS',\n",
        "    'CLITUS', 'PINDARUS', 'FIRST', 'SECOND', 'THIRD', 'FOURTH', 'BOTH',\n",
        "    'PLEBEIAN', 'PLEBEIANS', 'SOLDIER', 'SOLDIERS', 'MESSENGER', 'POET',\n",
        "    'COMMONER', 'COMMONERS', 'CITIZENS', 'SENATORS', 'ALL'\n",
        "}"
      ],
      "metadata": {
        "id": "15zgvVDzt6I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Clean raw text by removing FTLN numbers and normalizing whitespace\"\"\"\n",
        "    # Remove FTLN line numbers\n",
        "    text = re.sub(r'FTLN\\s+\\d+', '', text)\n",
        "    # Remove page headers like \"11 Julius Caesar ACT 1. SC. 1\"\n",
        "    text = re.sub(r'\\d+\\s+Julius Caesar\\s+ACT\\s+\\d+\\.\\s+SC\\.\\s+\\d+', '', text)\n",
        "    # Remove standalone numbers (line numbers)\n",
        "    text = re.sub(r'\\n\\s*\\d+\\s*\\n', '\\n', text)\n",
        "    # Remove stage directions in brackets\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def is_valid_speaker(name: str) -> bool:\n",
        "    name = name.upper().strip()\n",
        "    return any(char in name or name in char for char in CHARACTERS)"
      ],
      "metadata": {
        "id": "FdsX_cAetNEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_speeches = []\n",
        "current_act = None\n",
        "current_scene = None\n",
        "\n",
        "print(f\"Parsing Julius Caesar from {INPUT_PATH}\")\n",
        "\n",
        "with open(INPUT_PATH, 'r', encoding='utf-8') as f:\n",
        "    pages = json.load(f)\n",
        "\n",
        "\n",
        "for page_obj in pages:\n",
        "    page_num = page_obj.get('page', 0)\n",
        "\n",
        "    # Skip introductory pages\n",
        "    if page_num < 9:\n",
        "        continue\n",
        "\n",
        "    # Clean the text\n",
        "    text = clean_text(page_obj.get('raw', ''))\n",
        "\n",
        "    # --- Detect Structure (Act/Scene) ---\n",
        "    act_match = re.search(r'ACT\\s+(\\d+)', text, re.IGNORECASE)\n",
        "    if act_match:\n",
        "        current_act = int(act_match.group(1))\n",
        "\n",
        "    scene_match = re.search(r'Scene\\s+(\\d+)', text, re.IGNORECASE)\n",
        "    if scene_match:\n",
        "        current_scene = int(scene_match.group(1))\n",
        "\n",
        "    if not current_act:\n",
        "        continue\n",
        "\n",
        "    pattern = r'\\b([A-Z][A-Z\\s]{2,25}?)\\b\\s+([A-Z][a-z]|\\bO\\b|\\bAy\\b|\\bNo\\b|\\bWhat\\b|\\bWhy\\b|\\bHow\\b|\\bI\\b)'\n",
        "\n",
        "    matches = list(re.finditer(pattern, text))\n",
        "\n",
        "    for i, match in enumerate(matches):\n",
        "        speaker = match.group(1).strip()\n",
        "\n",
        "        if not is_valid_speaker(speaker):\n",
        "            continue\n",
        "\n",
        "        start_pos = match.start(2)\n",
        "        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
        "\n",
        "        dialogue = text[start_pos:end_pos].strip()\n",
        "\n",
        "        dialogue = re.sub(r'\\b(Enter|Exit|Exeunt|Re-enter|Aside|They exit|He exits|She exits|All exit).*?\\.', '', dialogue, flags=re.IGNORECASE)\n",
        "        dialogue = re.sub(r'\\(.*\\)', '', dialogue)\n",
        "        dialogue = ' '.join(dialogue.split())\n",
        "\n",
        "        if len(dialogue) > 20 and not dialogue.startswith(('ACT', 'Scene', 'Enter', 'Exit')):\n",
        "            all_speeches.append({\n",
        "                'act': current_act,\n",
        "                'scene': current_scene,\n",
        "                'speaker': speaker,\n",
        "                'text': dialogue\n",
        "            })\n",
        "\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtk4CSgitVj7",
        "outputId": "c5271295-71e4-4eb7-fabb-fa1dee409d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing Julius Caesar from /content/julius-caesar.json\n",
            "Processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(all_speeches)\n",
        "\n",
        "df.to_json(\"dialogue_chunks.json\", orient=\"records\", indent=2)\n",
        "print(\"\\nData saved to 'dialogue_chunks.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yoW1LhUuMdR",
        "outputId": "d5a13210-1d95-4b14-afd2-93edb535f326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data saved to 'dialogue_chunks.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "493f11ef"
      },
      "source": [
        "# def clean_unicode_and_numbers(text: str) -> str:\n",
        "#     \"\"\"Removes all Unicode characters and numbers from a string.\"\"\"\n",
        "#     # Remove numbers\n",
        "#     text = re.sub(r'\\d+', '', text)\n",
        "#     # Remove non-ASCII characters (often covers most 'unicode' characters in this context)\n",
        "#     text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "#     # Normalize whitespace after removals\n",
        "#     text = ' '.join(text.split())\n",
        "#     return text.strip()\n",
        "\n",
        "# df['text'] = df['text'].apply(clean_unicode_and_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7bc17d6"
      },
      "source": [
        "def transliterate_and_clean_text(text: str) -> str:\n",
        "    \"\"\"Transliterates unicode to ASCII, then removes numbers and normalizes whitespace.\"\"\"\n",
        "    # Transliterate Unicode characters to ASCII equivalents\n",
        "    text = unidecode(text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(transliterate_and_clean_text)"
      ],
      "metadata": {
        "id": "rMwtTfg6EGAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0086d2ef",
        "outputId": "e52115d1-97ba-4e6a-f03c-c6aae620050d"
      },
      "source": [
        "df.to_json(\"dialogue.json\", orient=\"records\", indent=2)\n",
        "print(\"\\nData (including cleaned text) saved again to 'dialogue.json'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data (including cleaned text) saved again to 'dialogue.json'\n"
          ]
        }
      ]
    }
  ]
}